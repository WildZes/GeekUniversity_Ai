{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lesson_8.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Введение в нейронные сети\n",
        "## Урок 8. GAN"
      ],
      "metadata": {
        "id": "V3yVi_O2f01H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Обучите нейронную сеть любой архитектуры, которой не было на курсе, либо нейронную сеть разобранной архитектуры, но на том датасете, которого не было на уроках. Сделайте анализ того, что вам помогло в улучшения работы нейронной сети"
      ],
      "metadata": {
        "id": "wPiejghJw89-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reYQVcewfZjZ",
        "outputId": "fa993a31-68f0-4a56-ce0e-c1b8e08836d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.20-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (from opendatasets) (1.5.12)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from opendatasets) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from opendatasets) (4.62.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.15.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (5.0.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.23.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2021.10.8)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (3.0.4)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.20\n"
          ]
        }
      ],
      "source": [
        "# !pip install opendatasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od"
      ],
      "metadata": {
        "id": "aG4zSpJ4fdd6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "od.download(\"https://github.com/JurgenPalsma/swarmex/archive/refs/heads/master.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pyV3BrPfhLU",
        "outputId": "4375a8d0-3d5e-491d-fef4-77ed00554214"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/JurgenPalsma/swarmex/archive/refs/heads/master.zip to ./swarmex-master.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20684800it [00:02, 10296898.32it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/swarmex-master.zip\" -d \"/content/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRY61Pe4fpTL",
        "outputId": "873839dd-cec5-4961-a45d-87c63dc25404"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/swarmex-master.zip\n",
            "00453379dfe6fef3416dcac85a80c958c01bac07\n",
            "   creating: /content/swarmex-master/\n",
            "  inflating: /content/swarmex-master/.gitignore  \n",
            "  inflating: /content/swarmex-master/README.md  \n",
            "   creating: /content/swarmex-master/analysis/\n",
            "  inflating: /content/swarmex-master/analysis/indepth_csfla_tuning.html  \n",
            "  inflating: /content/swarmex-master/analysis/indepth_csfla_tuning.ipynb  \n",
            "  inflating: /content/swarmex-master/analysis/indepth_pso_tuning.html  \n",
            "  inflating: /content/swarmex-master/analysis/indepth_pso_tuning.ipynb  \n",
            "  inflating: /content/swarmex-master/analysis/preliminary_csfla_tuning_analysis.html  \n",
            "  inflating: /content/swarmex-master/analysis/preliminary_csfla_tuning_analysis.ipynb  \n",
            "  inflating: /content/swarmex-master/analysis/preliminary_pso_tuning_analysis.html  \n",
            "  inflating: /content/swarmex-master/analysis/preliminary_pso_tuning_analysis.ipynb  \n",
            "  inflating: /content/swarmex-master/analysis/test_data_analysis.html  \n",
            "  inflating: /content/swarmex-master/analysis/test_data_analysis.ipynb  \n",
            "  inflating: /content/swarmex-master/analysis/toolz.py  \n",
            "   creating: /content/swarmex-master/config/\n",
            "   creating: /content/swarmex-master/config/algos/\n",
            "  inflating: /content/swarmex-master/config/algos/csfla.json  \n",
            "  inflating: /content/swarmex-master/config/algos/csfla_configs.json  \n",
            "  inflating: /content/swarmex-master/config/algos/csfla_param_exp_configs.json  \n",
            "  inflating: /content/swarmex-master/config/algos/csfla_params_config_2.json  \n",
            "  inflating: /content/swarmex-master/config/algos/pso.json  \n",
            "  inflating: /content/swarmex-master/config/algos/pso_configs.json  \n",
            "  inflating: /content/swarmex-master/config/algos/pso_configs_2.json  \n",
            "  inflating: /content/swarmex-master/config/algos/pso_configs_3.json  \n",
            "  inflating: /content/swarmex-master/config/algos/pso_param_exp_configs.json  \n",
            "  inflating: /content/swarmex-master/config/config.json  \n",
            "  inflating: /content/swarmex-master/config/demo.json  \n",
            "  inflating: /content/swarmex-master/config/logging.json  \n",
            "  inflating: /content/swarmex-master/config/paramsexperiment1config.json  \n",
            "  inflating: /content/swarmex-master/config/testing_config.json  \n",
            "  inflating: /content/swarmex-master/config/training_config.json  \n",
            "  inflating: /content/swarmex-master/csfla.py  \n",
            "   creating: /content/swarmex-master/data/\n",
            "   creating: /content/swarmex-master/data/EUR_GBP/\n",
            "  inflating: /content/swarmex-master/data/EUR_GBP/fx-spot_EUR_GBP_10min_201306.txt  \n",
            "  inflating: /content/swarmex-master/data/EUR_GBP/fx-spot_EUR_GBP_10min_201307.txt  \n",
            "  inflating: /content/swarmex-master/data/EUR_GBP/fx-spot_EUR_GBP_10min_201308.txt  \n",
            "  inflating: /content/swarmex-master/data/EUR_GBP/fx-spot_EUR_GBP_10min_201309.txt  \n",
            "  inflating: /content/swarmex-master/data/EUR_GBP/fx-spot_EUR_GBP_10min_201310.txt  \n",
            "  inflating: /content/swarmex-master/data/EUR_GBP/fx-spot_EUR_GBP_10min_201311.txt  \n",
            "  inflating: /content/swarmex-master/data/EUR_GBP/fx-spot_EUR_GBP_10min_201312.txt  \n",
            "  inflating: /content/swarmex-master/data/EUR_GBP/fx-spot_EUR_GBP_10min_201401.txt  \n",
            "  inflating: /content/swarmex-master/data/EUR_GBP/fx-spot_EUR_GBP_10min_201402.txt  \n",
            "  inflating: /content/swarmex-master/data/EUR_GBP/fx-spot_EUR_GBP_10min_201403.txt  \n",
            "  inflating: /content/swarmex-master/data/EUR_GBP/fx-spot_EUR_GBP_10min_201404.txt  \n",
            "  inflating: /content/swarmex-master/data/EUR_GBP/fx-spot_EUR_GBP_10min_201405.txt  \n",
            "   creating: /content/swarmex-master/data/EUR_USD/\n",
            "  inflating: /content/swarmex-master/data/EUR_USD/fx-spot_EUR_USD_10min_201306.txt  \n",
            "  inflating: /content/swarmex-master/data/EUR_USD/fx-spot_EUR_USD_10min_201307.txt  \n",
            "  inflating: /content/swarmex-master/data/EUR_USD/fx-spot_EUR_USD_10min_201308.txt  \n",
            "  inflating: /content/swarmex-master/data/EUR_USD/fx-spot_EUR_USD_10min_201309.txt  \n",
            "  inflating: /content/swarmex-master/data/EUR_USD/fx-spot_EUR_USD_10min_201310.txt  \n",
            "  inflating: /content/swarmex-master/data/EUR_USD/fx-spot_EUR_USD_10min_201311.txt  \n",
            "  inflating: /content/swarmex-master/data/EUR_USD/fx-spot_EUR_USD_10min_201312.txt  \n",
            "  inflating: /content/swarmex-master/data/EUR_USD/fx-spot_EUR_USD_10min_201401.txt  \n",
            "  inflating: /content/swarmex-master/data/EUR_USD/fx-spot_EUR_USD_10min_201402.txt  \n",
            "  inflating: /content/swarmex-master/data/EUR_USD/fx-spot_EUR_USD_10min_201403.txt  \n",
            "  inflating: /content/swarmex-master/data/EUR_USD/fx-spot_EUR_USD_10min_201404.txt  \n",
            "  inflating: /content/swarmex-master/data/EUR_USD/fx-spot_EUR_USD_10min_201405.txt  \n",
            "   creating: /content/swarmex-master/data/GBP_CHF/\n",
            "  inflating: /content/swarmex-master/data/GBP_CHF/fx-spot_GBP_CHF_10min_201306.txt  \n",
            "  inflating: /content/swarmex-master/data/GBP_CHF/fx-spot_GBP_CHF_10min_201307.txt  \n",
            "  inflating: /content/swarmex-master/data/GBP_CHF/fx-spot_GBP_CHF_10min_201308.txt  \n",
            "  inflating: /content/swarmex-master/data/GBP_CHF/fx-spot_GBP_CHF_10min_201309.txt  \n",
            "  inflating: /content/swarmex-master/data/GBP_CHF/fx-spot_GBP_CHF_10min_201310.txt  \n",
            "  inflating: /content/swarmex-master/data/GBP_CHF/fx-spot_GBP_CHF_10min_201311.txt  \n",
            "  inflating: /content/swarmex-master/data/GBP_CHF/fx-spot_GBP_CHF_10min_201312.txt  \n",
            "  inflating: /content/swarmex-master/data/GBP_CHF/fx-spot_GBP_CHF_10min_201401.txt  \n",
            "  inflating: /content/swarmex-master/data/GBP_CHF/fx-spot_GBP_CHF_10min_201402.txt  \n",
            "  inflating: /content/swarmex-master/data/GBP_CHF/fx-spot_GBP_CHF_10min_201403.txt  \n",
            "  inflating: /content/swarmex-master/data/GBP_CHF/fx-spot_GBP_CHF_10min_201404.txt  \n",
            "  inflating: /content/swarmex-master/data/GBP_CHF/fx-spot_GBP_CHF_10min_201405.txt  \n",
            "   creating: /content/swarmex-master/data/GBP_USD/\n",
            "  inflating: /content/swarmex-master/data/GBP_USD/fx-spot_GBP_USD_10min_201306.txt  \n",
            "  inflating: /content/swarmex-master/data/GBP_USD/fx-spot_GBP_USD_10min_201307.txt  \n",
            "  inflating: /content/swarmex-master/data/GBP_USD/fx-spot_GBP_USD_10min_201308.txt  \n",
            "  inflating: /content/swarmex-master/data/GBP_USD/fx-spot_GBP_USD_10min_201309.txt  \n",
            "  inflating: /content/swarmex-master/data/GBP_USD/fx-spot_GBP_USD_10min_201310.txt  \n",
            "  inflating: /content/swarmex-master/data/GBP_USD/fx-spot_GBP_USD_10min_201311.txt  \n",
            "  inflating: /content/swarmex-master/data/GBP_USD/fx-spot_GBP_USD_10min_201312.txt  \n",
            "  inflating: /content/swarmex-master/data/GBP_USD/fx-spot_GBP_USD_10min_201401.txt  \n",
            "  inflating: /content/swarmex-master/data/GBP_USD/fx-spot_GBP_USD_10min_201402.txt  \n",
            "  inflating: /content/swarmex-master/data/GBP_USD/fx-spot_GBP_USD_10min_201403.txt  \n",
            "  inflating: /content/swarmex-master/data/GBP_USD/fx-spot_GBP_USD_10min_201404.txt  \n",
            "  inflating: /content/swarmex-master/data/GBP_USD/fx-spot_GBP_USD_10min_201405.txt  \n",
            "  inflating: /content/swarmex-master/data/ga-ks-values.csv  \n",
            "  inflating: /content/swarmex-master/data/pso-ks-values.csv  \n",
            "   creating: /content/swarmex-master/dc/\n",
            "   creating: /content/swarmex-master/dc/bin/\n",
            "  inflating: /content/swarmex-master/dc/bin/.project  \n",
            "  inflating: /content/swarmex-master/dc/bin/dc-ga.jar  \n",
            "  inflating: /content/swarmex-master/dc/bin/dc-server.jar  \n",
            "  inflating: /content/swarmex-master/dc/bin/dc-server.py  \n",
            "  inflating: /content/swarmex-master/dc/dc-ga.jar  \n",
            "  inflating: /content/swarmex-master/dc/dc-server.jar  \n",
            "  inflating: /content/swarmex-master/dc/dc-server.py  \n",
            "   creating: /content/swarmex-master/docs/\n",
            "   creating: /content/swarmex-master/docs/followups/\n",
            "  inflating: /content/swarmex-master/docs/followups/follow up 07_08.pdf  \n",
            "  inflating: /content/swarmex-master/docs/followups/follow up 14_08.pdf  \n",
            "  inflating: /content/swarmex-master/docs/followups/follow up 30_07.pdf  \n",
            "   creating: /content/swarmex-master/docs/uml/\n",
            "  inflating: /content/swarmex-master/docs/uml/uml.html  \n",
            "  inflating: /content/swarmex-master/docs/uml/uml.pdf  \n",
            "  inflating: /content/swarmex-master/docs/uml/uml.png  \n",
            "  inflating: /content/swarmex-master/fitness.py  \n",
            "  inflating: /content/swarmex-master/frog.py  \n",
            "  inflating: /content/swarmex-master/gateway.py  \n",
            "  inflating: /content/swarmex-master/individual.py  \n",
            "  inflating: /content/swarmex-master/javafitness.py  \n",
            "  inflating: /content/swarmex-master/main.py  \n",
            "  inflating: /content/swarmex-master/optimizer.py  \n",
            "  inflating: /content/swarmex-master/particle.py  \n",
            "  inflating: /content/swarmex-master/pso.py  \n",
            "  inflating: /content/swarmex-master/requirements.txt  \n",
            "  inflating: /content/swarmex-master/results.zip  \n",
            "  inflating: /content/swarmex-master/tools.py  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd swarmex-master/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ol544qCgZzP",
        "outputId": "39eaaabd-ffb9-49a2-8d37-13d77d0fd1a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/swarmex-master\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install py4j"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MQ4gfH0j3PN",
        "outputId": "4769b130-810b-49c9-b078-973001ec96b5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting py4j\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 5.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: py4j\n",
            "Successfully installed py4j-0.10.9.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py -c ./config/demo.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AJ8PI6Hgr4X",
        "outputId": "065f458e-3466-4b7f-93f3-a41f515e35b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transaction cost: 1.0E-5\n",
            "Slippage allowance: 0.0\n",
            "Loading directional changes data...\n",
            "DC curves:\n",
            "0.010%: {length =   619, meanRatio[up] = 0.68, meanRatio[down] = 0.48}\n",
            "0.013%: {length =   569, meanRatio[up] = 0.71, meanRatio[down] = 0.53}\n",
            "0.015%: {length =   503, meanRatio[up] = 0.73, meanRatio[down] = 0.61}\n",
            "0.018%: {length =   473, meanRatio[up] = 0.76, meanRatio[down] = 0.63}\n",
            "0.020%: {length =   449, meanRatio[up] = 0.73, meanRatio[down] = 0.67}\n",
            "\n",
            "Starting GA...\n",
            "Random seed: 1643320951368\n",
            "Training budget: 500000.0\n",
            "Test budget: 500000.0\n",
            "\n",
            "Generation\tBest\tWorst\tAverage\n",
            "0\t    0.000674\t-9999.000000\t -149.985049\n",
            "1\t    0.000723\t-9999.000000\t  -69.993015\n",
            "2\t    0.000839\t-9999.000000\t  -29.996948\n",
            "3\t    0.000847\t   -0.000847\t    0.000167\n",
            "4\t    0.000865\t-9999.000000\t   -9.998683\n",
            "5\t    0.000923\t-9999.000000\t  -19.997536\n",
            "6\t    0.000932\t   -0.000529\t    0.000610\n",
            "7\t    0.000947\t-9999.000000\t   -9.998320\n",
            "8\t    0.000947\t   -0.000868\t    0.000733\n",
            "9\t    0.000969\t   -0.000429\t    0.000762\n",
            "10\t    0.000992\t-9999.000000\t   -9.998220\n",
            "11\t    0.001018\t   -0.000581\t    0.000823\n",
            "12\t    0.001018\t   -0.000735\t    0.000832\n",
            "13\t    0.001060\t   -0.000907\t    0.000836\n",
            "14\t    0.001072\t   -0.000696\t    0.000853\n",
            "15\t    0.001072\t-9999.000000\t  -29.996143\n",
            "16\t    0.001072\t-9999.000000\t   -9.998111\n",
            "17\t    0.001072\t   -0.001231\t    0.000913\n",
            "18\t    0.001077\t   -0.000709\t    0.000931\n",
            "19\t    0.001077\t   -0.000886\t    0.000939\n",
            "20\t    0.001077\t-9999.000000\t   -9.998046\n",
            "21\t    0.001077\t   -0.000973\t    0.000957\n",
            "22\t    0.001077\t-9999.000000\t   -9.998035\n",
            "23\t    0.001077\t-9999.000000\t   -9.998026\n",
            "24\t    0.001077\t   -0.000717\t    0.000988\n",
            "25\t    0.001077\t-9999.000000\t   -9.998038\n",
            "26\t    0.001077\t   -0.000994\t    0.000987\n",
            "27\t    0.001077\t-9999.000000\t  -19.997015\n",
            "28\t    0.001077\t-9999.000000\t  -19.997013\n",
            "29\t    0.001077\t   -0.001067\t    0.000983\n",
            "30\t    0.001077\t-9999.000000\t   -9.998000\n",
            "31\t    0.001077\t-9999.000000\t  -19.997014\n",
            "32\t    0.001077\t   -0.000844\t    0.000995\n",
            "33\t    0.001077\t-9999.000000\t  -19.997015\n",
            "34\t    0.001077\t   -0.000918\t    0.001007\n",
            "Number of transactions of best individual in training: 105\n",
            "0.010%: 0.523627\n",
            "0.013%: 0.294356\n",
            "0.015%: 0.299094\n",
            "0.018%: 0.611731\n",
            "0.020%: 0.725078\n",
            "Starting GA...\n",
            "Random seed: 1643320955616\n",
            "Training budget: 500000.0\n",
            "Test budget: 500000.0\n",
            "\n",
            "Generation\tBest\tWorst\tAverage\n",
            "0\t    0.000834\t-9999.000000\t -129.987048\n",
            "1\t    0.000834\t-9999.000000\t  -69.993021\n",
            "2\t    0.000834\t-9999.000000\t  -39.995955\n",
            "3\t    0.000876\t-9999.000000\t   -9.998866\n",
            "4\t    0.000999\t   -0.000828\t    0.000264\n",
            "5\t    0.000999\t   -0.000656\t    0.000383\n",
            "6\t    0.004337\t   -0.000873\t    0.000521\n",
            "7\t    0.004337\t   -0.000495\t    0.000657\n",
            "8\t    0.004337\t-9999.000000\t  -19.997288\n",
            "9\t    0.005900\t   -0.000857\t    0.000752\n",
            "10\t    0.005900\t-9999.000000\t  -19.997246\n",
            "11\t    0.005900\t   -0.000812\t    0.000772\n",
            "12\t    0.005900\t   -0.000418\t    0.000800\n",
            "13\t    0.005900\t   -0.000799\t    0.000790\n",
            "14\t    0.005900\t   -0.000855\t    0.000804\n",
            "15\t    0.005900\t-9999.000000\t  -19.997176\n",
            "16\t    0.005900\t   -0.000647\t    0.000876\n",
            "17\t    0.005900\t-9999.000000\t  -19.997119\n",
            "18\t    0.005900\t   -0.000916\t    0.000899\n",
            "19\t    0.005900\t   -0.001133\t    0.000905\n",
            "20\t    0.006129\t-9999.000000\t   -9.998076\n",
            "21\t    0.006129\t-9999.000000\t   -9.998040\n",
            "22\t    0.006559\t-9999.000000\t   -9.998032\n",
            "23\t    0.006559\t-9999.000000\t   -9.998039\n",
            "24\t    0.006559\t-9999.000000\t  -39.995048\n",
            "25\t    0.006559\t-9999.000000\t   -9.998026\n",
            "26\t    0.006559\t   -0.001016\t    0.000973\n",
            "27\t    0.006559\t-9999.000000\t   -9.998022\n",
            "28\t    0.006559\t   -0.000786\t    0.000998\n",
            "29\t    0.006559\t-9999.000000\t   -9.998024\n",
            "30\t    0.006559\t-9999.000000\t   -9.998019\n",
            "31\t    0.006559\t-9999.000000\t   -9.998026\n",
            "32\t    0.006559\t-9999.000000\t   -9.998021\n",
            "33\t    0.006559\t   -0.000923\t    0.000991\n",
            "34\t    0.006559\t-9999.000000\t  -19.997020\n",
            "Number of transactions of best individual in training: 58\n",
            "0.010%: 0.328328\n",
            "0.013%: 0.343883\n",
            "0.015%: 0.418960\n",
            "0.018%: 0.698828\n",
            "0.020%: 0.649857\n",
            "Starting GA...\n",
            "Random seed: 1643320959611\n",
            "Training budget: 500000.0\n",
            "Test budget: 500000.0\n",
            "\n",
            "Generation\tBest\tWorst\tAverage\n",
            "0\t    0.003260\t-9999.000000\t -159.984050\n",
            "1\t    0.003260\t-9999.000000\t  -49.995008\n",
            "2\t    0.003260\t-9999.000000\t  -29.996940\n",
            "3\t    0.003260\t-9999.000000\t   -9.998821\n",
            "4\t    0.003260\t-9999.000000\t   -9.998694\n",
            "5\t    0.003260\t   -0.000697\t    0.000391\n",
            "6\t    0.003260\t   -0.000703\t    0.000466\n",
            "7\t    0.003260\t-9999.000000\t   -9.998413\n",
            "8\t    0.003260\t-9999.000000\t  -19.997326\n",
            "9\t    0.003260\t   -0.000816\t    0.000724\n",
            "10\t    0.003260\t   -0.000832\t    0.000757\n",
            "11\t    0.003260\t-9999.000000\t   -9.998223\n",
            "12\t    0.003260\t-9999.000000\t   -9.998190\n",
            "13\t    0.003260\t-9999.000000\t   -9.998165\n",
            "14\t    0.003260\t   -0.000823\t    0.000869\n",
            "15\t    0.003260\t   -0.000892\t    0.000891\n",
            "16\t    0.003260\t   -0.000947\t    0.000895\n",
            "17\t    0.003260\t-9999.000000\t   -9.998096\n",
            "18\t    0.003260\t   -0.000975\t    0.000905\n",
            "19\t    0.003260\t-9999.000000\t  -19.997101\n",
            "20\t    0.003260\t-9999.000000\t  -19.997059\n",
            "21\t    0.003260\t-9999.000000\t  -19.997086\n",
            "22\t    0.004289\t   -0.000745\t    0.000925\n",
            "23\t    0.004289\t-9999.000000\t   -9.998064\n",
            "24\t    0.004289\t   -0.001013\t    0.000911\n",
            "25\t    0.004289\t-9999.000000\t   -9.998086\n",
            "26\t    0.004289\t-9999.000000\t   -9.998053\n",
            "27\t    0.004289\t-9999.000000\t   -9.998051\n",
            "28\t    0.004289\t-9999.000000\t   -9.998053\n",
            "29\t    0.004289\t-9999.000000\t   -9.998060\n",
            "30\t    0.004289\t-9999.000000\t  -19.997060\n",
            "31\t    0.004289\t   -0.000904\t    0.000957\n",
            "32\t    0.004289\t-9999.000000\t   -9.998040\n",
            "33\t    0.004289\t-9999.000000\t  -49.994045\n",
            "34\t    0.004289\t   -0.000987\t    0.000974\n",
            "Number of transactions of best individual in training: 37\n",
            "0.010%: 0.175381\n",
            "0.013%: 0.459893\n",
            "0.015%: 0.357499\n",
            "0.018%: 0.458270\n",
            "0.020%: 0.125945\n",
            "Transaction cost: 1.0E-5\n",
            "Slippage allowance: 0.0\n",
            "Loading directional changes data...\n",
            "DC curves:\n",
            "0.010%: {length =   619, meanRatio[up] = 0.68, meanRatio[down] = 0.48}\n",
            "0.013%: {length =   569, meanRatio[up] = 0.71, meanRatio[down] = 0.53}\n",
            "0.015%: {length =   503, meanRatio[up] = 0.73, meanRatio[down] = 0.61}\n",
            "0.018%: {length =   473, meanRatio[up] = 0.76, meanRatio[down] = 0.63}\n",
            "0.020%: {length =   449, meanRatio[up] = 0.73, meanRatio[down] = 0.67}\n",
            "\n",
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "Transaction cost: 1.0E-5\n",
            "Slippage allowance: 0.0\n",
            "Loading directional changes data...\n",
            "DC curves:\n",
            "0.010%: {length =   619, meanRatio[up] = 0.68, meanRatio[down] = 0.48}\n",
            "0.013%: {length =   569, meanRatio[up] = 0.71, meanRatio[down] = 0.53}\n",
            "0.015%: {length =   503, meanRatio[up] = 0.73, meanRatio[down] = 0.61}\n",
            "0.018%: {length =   473, meanRatio[up] = 0.76, meanRatio[down] = 0.63}\n",
            "0.020%: {length =   449, meanRatio[up] = 0.73, meanRatio[down] = 0.67}\n",
            "\n",
            "INFO:pso:Initialize PSO with swarm_size:50, v_max:150.000000, w_inertia:0.850000, w_memory:0.450000, w_neigh:0.050000, k:5, vel_conv_thresholds:0.000050, neighbourhood:<Neighbourhood.GLOBAL: 0>, max_iter:7\n",
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "Process Process-5:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/swarmex-master/pso.py\", line 206, in run_pso_from_config\n",
            "    max_iter= config['max_iter'])\n",
            "  File \"/content/swarmex-master/pso.py\", line 172, in run_pso\n",
            "    particle = pso.optimize(fitness_function)\n",
            "  File \"/content/swarmex-master/pso.py\", line 72, in optimize\n",
            "    if (self.__min_vel(d)):\n",
            "  File \"/content/swarmex-master/pso.py\", line 111, in __min_vel\n",
            "    return (abs(d.max()) < self.vel_conv_threshold)\n",
            "TypeError: '<' not supported between instances of 'float' and 'tuple'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Поиск для решения задачи начал со [статьи](https://iopscience.iop.org/article/10.1088/1742-6596/1641/1/012067/pdf). В статье выглядят перспективными результаты исследований:  \n",
        ">\"William H Hidayatno A and Zahra A A, 2014 Aplikasi Jaringan Saraf Tiruan Perambatan Balik Untuk\n",
        "Prakiraan Valuta GBP/USD Dalam Forex Trading Transient 3, 4 p. 1–8.\"  \n",
        "\n",
        "В связи с этим решил использовать нейросеть с использованием _partical swarm optimization_.  \n",
        "Для применения модели выбрал работу JurgenPalsma на [github](https://github.com/JurgenPalsma/swarmex).  \n",
        "Полноценный тестовый запус осуществить не удалось, поэтому обратился к другому источнику."
      ],
      "metadata": {
        "id": "n6NLpCvLjUrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pyswarms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIyn6Yb6xOt0",
        "outputId": "cd643ffa-a348-4416-bd36-0acbb4cebaf9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyswarms\n",
            "  Downloading pyswarms-1.3.0-py2.py3-none-any.whl (104 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▏                            | 10 kB 26.8 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 20 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 30 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 40 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 51 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 61 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 81 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 92 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 104 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from pyswarms) (3.2.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from pyswarms) (3.13)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyswarms) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pyswarms) (4.62.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyswarms) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyswarms) (1.19.5)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from pyswarms) (21.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.3.1->pyswarms) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.3.1->pyswarms) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.3.1->pyswarms) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.3.1->pyswarms) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=1.3.1->pyswarms) (1.15.0)\n",
            "Installing collected packages: pyswarms\n",
            "Successfully installed pyswarms-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ..\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rdybsInyipd",
        "outputId": "c9980f88-1f84-4209-bc7e-fc94c7515d3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "\n",
        "# Import PySwarms\n",
        "import pyswarms as ps\n",
        "\n",
        "# Some more magic so that the notebook will reload external python modules;\n",
        "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "Vts4nmv_w3Gf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# список признаков, по которым будем учить\n",
        "channelIndexes = [0, 1, 2, 3]\n",
        "#channelIndexes = [0,1,2]\n",
        "\n",
        "# длина истории для работы\n",
        "xLen = 14\n",
        "# отступ тестов от тренировок\n",
        "bias = 7\n",
        "\n",
        "# шаг по данным для построения обучающих примеров\n",
        "step = 1\n",
        "\n",
        "# горизонт предсказания\n",
        "future = 1\n",
        "\n",
        "\n",
        "# параметры модели для обучения\n",
        "batch_size = 8\n",
        "epochs = 10\n",
        "\n",
        "train_split_percents = 80"
      ],
      "metadata": {
        "id": "K1OwSXY1xMep"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_get(path_to_csv, start_date, batch_size):\n",
        "  df = pd.read_csv(path_to_csv, usecols=['<DATE>','<HIGH>','<LOW>'],\n",
        "                   index_col=['<DATE>'], parse_dates=['<DATE>'],) #sep=';')\n",
        "  df = df[df.index >= pd.to_datetime(start_date)]\n",
        "  df[\"HLAvg\"] = df['<HIGH>'].add(df['<LOW>']).div(2)\n",
        "  del df['<HIGH>']\n",
        "  del df['<LOW>']\n",
        "\n",
        "  # Simple Moving Average\n",
        "  df['MA'] = df['HLAvg'].rolling(window=14).mean()\n",
        "  # Log Returns\n",
        "  df['Returns'] = np.log(df['MA']/df['MA'].shift(1))\n",
        "  \n",
        "  df.dropna(how='any', inplace=True)\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "ctqUJzSLx_KJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Попытка применения нейросети на данных с котировками CHFUSD"
      ],
      "metadata": {
        "id": "AHrqi12J-Che"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = data_get('./CHFUSD_210101_220118_1H.csv', '01.01.2021', batch_size)\n",
        "# Simple Moving Average\n",
        "df['MA'] = df['HLAvg'].rolling(window=xLen).mean()\n",
        "# Log Returns\n",
        "df['Returns'] = np.log(df['MA']/df['MA'].shift(1))\n",
        "df.dropna(how='any', inplace=True)\n",
        "df = df[df.shape[0] % batch_size:]\n",
        "validation_size = round(df.shape[0]*0.2)\n",
        "test_size = round(df.shape[0]*0.2)\n",
        "df_train = df[:- validation_size - test_size]\n",
        "df_validation = df[- validation_size - test_size - xLen:- test_size]\n",
        "df_test = df[- test_size - xLen:]\n",
        "df_train.shape, df_validation.shape, df_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWJ2XQqUyCZT",
        "outputId": "95d6cc4f-d867-49f7-f660-c7791e65e943"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-01-30 23:31:37,608 - numexpr.utils - INFO - NumExpr defaulting to 2 threads.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4066, 3), (1369, 3), (1369, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train(values, window_size):\n",
        "    X, y = [], []\n",
        "    len_values = len(values)\n",
        "    for i in range(window_size, len_values):\n",
        "        X.append(values[i-window_size:i])\n",
        "        y.append(values[i])\n",
        "    X, y = np.asarray(X), np.asarray(y)\n",
        "    X = np.reshape(X, (X.shape[0], X.shape[1]))\n",
        "    y = np.reshape(y, y.shape[0])\n",
        "    return X, y\n",
        "\n",
        "def get_val(values, window_size):\n",
        "    X = []\n",
        "    len_values = len(values)\n",
        "    for i in range(window_size, len_values):\n",
        "        X.append(values[i-window_size:i])\n",
        "    X = np.asarray(X)\n",
        "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
        "    y = values[-X.shape[0]:]\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "sPzhUvwAzR7K"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = get_train(df[['Returns']].values, xLen)\n",
        "y[y<-0.000001] = -1\n",
        "y[y>0.000001] = 1\n",
        "y = np.where((y>-0.000001)&(y<0.000001), 0, y)\n",
        "y = y.astype(int)\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GypjQHEwzwJ2",
        "outputId": "97d0de63-b195-4bbe-f098-e68315372117"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6762, 14), (6762,))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward propagation\n",
        "def forward_prop(params):\n",
        "    \"\"\"Forward propagation as objective function\n",
        "\n",
        "    This computes for the forward propagation of the neural network, as\n",
        "    well as the loss. It receives a set of parameters that must be\n",
        "    rolled-back into the corresponding weights and biases.\n",
        "\n",
        "    Inputs\n",
        "    ------\n",
        "    params: np.ndarray\n",
        "        The dimensions should include an unrolled version of the\n",
        "        weights and biases.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    float\n",
        "        The computed negative log-likelihood loss given the parameters\n",
        "    \"\"\"\n",
        "    # Neural network architecture\n",
        "    n_inputs = 14\n",
        "    n_hidden = 370\n",
        "    n_classes = 3\n",
        "\n",
        "    # Roll-back the weights and biases\n",
        "    W1 = params[0:5180].reshape((n_inputs,n_hidden))\n",
        "    b1 = params[5180:5550].reshape((n_hidden,))\n",
        "    W2 = params[5550:6660].reshape((n_hidden,n_classes))\n",
        "    b2 = params[6660:6663].reshape((n_classes,))\n",
        "\n",
        "    # Perform forward propagation\n",
        "    z1 = X.dot(W1) + b1  # Pre-activation in Layer 1\n",
        "    a1 = np.tanh(z1)     # Activation in Layer 1\n",
        "    z2 = a1.dot(W2) + b2 # Pre-activation in Layer 2\n",
        "    logits = z2          # Logits for Layer 2\n",
        "\n",
        "    # Compute for the softmax of the logits\n",
        "    exp_scores = np.exp(logits)\n",
        "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
        "\n",
        "    # Compute for the negative log likelihood\n",
        "    N = 6762 # Number of samples\n",
        "    corect_logprobs = -np.log(probs[range(N)])\n",
        "    loss = np.sum(corect_logprobs) / N\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "QrS_t9lWz4zO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x):\n",
        "    \"\"\"Higher-level method to do forward_prop in the\n",
        "    whole swarm.\n",
        "\n",
        "    Inputs\n",
        "    ------\n",
        "    x: numpy.ndarray of shape (n_particles, dimensions)\n",
        "        The swarm that will perform the search\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    numpy.ndarray of shape (n_particles, )\n",
        "        The computed loss for each particle\n",
        "    \"\"\"\n",
        "    n_particles = x.shape[0]\n",
        "    j = [forward_prop(x[i]) for i in range(n_particles)]\n",
        "    return np.array(j)"
      ],
      "metadata": {
        "id": "IpYtqIjlz_TP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize swarm\n",
        "options = {'c1': 0.5, 'c2': 0.3, 'w':0.9}\n",
        "\n",
        "# Call instance of PSO\n",
        "dimensions = y.shape[0]\n",
        "optimizer = ps.single.GlobalBestPSO(n_particles=100, dimensions=dimensions, options=options)\n",
        "\n",
        "# Perform optimization\n",
        "cost, pos = optimizer.optimize(f, iters=100, verbose=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKpkRgX-0Cxf",
        "outputId": "f6fe22a5-fd7d-411e-ac26-4efca84e81cf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-01-30 23:33:11,132 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n",
            "pyswarms.single.global_best: 100%|██████████|100/100, best_cost=3.3\n",
            "2022-01-30 23:53:59,264 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 3.2960114346644582, best pos: [0.28784608 0.54720764 0.02994148 ... 0.77016003 0.50483204 0.11480229]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, pos):\n",
        "    \"\"\"\n",
        "    Use the trained weights to perform class predictions.\n",
        "\n",
        "    Inputs\n",
        "    ------\n",
        "    X: numpy.ndarray\n",
        "        Input Iris dataset\n",
        "    pos: numpy.ndarray\n",
        "        Position matrix found by the swarm. Will be rolled\n",
        "        into weights and biases.\n",
        "    \"\"\"\n",
        "    # Neural network architecture\n",
        "    n_inputs = 14\n",
        "    n_hidden = 370\n",
        "    n_classes = 3\n",
        "\n",
        "    # Roll-back the weights and biases\n",
        "    W1 = pos[0:5180].reshape((n_inputs,n_hidden))\n",
        "    b1 = pos[5180:5550].reshape((n_hidden,))\n",
        "    W2 = pos[5550:6660].reshape((n_hidden,n_classes))\n",
        "    b2 = pos[6660:6663].reshape((n_classes,))\n",
        "\n",
        "    # Perform forward propagation\n",
        "    z1 = X.dot(W1) + b1  # Pre-activation in Layer 1\n",
        "    a1 = np.tanh(z1)     # Activation in Layer 1\n",
        "    z2 = a1.dot(W2) + b2 # Pre-activation in Layer 2\n",
        "    logits = z2          # Logits for Layer 2\n",
        "\n",
        "    y_pred = np.argmax(logits, axis=1)\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "pzNl37YPKET7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(predict(X, pos) == y).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXsfEiPXbC6X",
        "outputId": "8c258cef-afd6-4af3-f2a0-d9ab21c7c2e8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0048802129547471165"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Попытка применения нейросети по [образцу](https://pyswarms.readthedocs.io/en/development/examples/custom_objective_function.html)"
      ],
      "metadata": {
        "id": "nB638ueJ-NNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the iris dataset\n",
        "data = load_iris()\n",
        "\n",
        "# Store the features as X and the labels as y\n",
        "X = data.data\n",
        "y = data.target"
      ],
      "metadata": {
        "id": "Fb5SHNMz0JMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGx1s3Rr1ipV",
        "outputId": "a375890f-192c-4d08-ea9a-2a7da50d67dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((150, 4), (150,))"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[0].shape, X[160:163]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzRPMye31qul",
        "outputId": "bc8e2cb5-79ce-484b-df3e-41b307be7efa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4,), array([], shape=(0, 4), dtype=float64))"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward propagation\n",
        "def forward_prop(params):\n",
        "    \"\"\"Forward propagation as objective function\n",
        "\n",
        "    This computes for the forward propagation of the neural network, as\n",
        "    well as the loss. It receives a set of parameters that must be\n",
        "    rolled-back into the corresponding weights and biases.\n",
        "\n",
        "    Inputs\n",
        "    ------\n",
        "    params: np.ndarray\n",
        "        The dimensions should include an unrolled version of the\n",
        "        weights and biases.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    float\n",
        "        The computed negative log-likelihood loss given the parameters\n",
        "    \"\"\"\n",
        "    # Neural network architecture\n",
        "    n_inputs = 4\n",
        "    n_hidden = 20\n",
        "    n_classes = 3\n",
        "\n",
        "    # Roll-back the weights and biases\n",
        "    W1 = params[0:80].reshape((n_inputs,n_hidden))\n",
        "    b1 = params[80:100].reshape((n_hidden,))\n",
        "    W2 = params[100:160].reshape((n_hidden,n_classes))\n",
        "    b2 = params[160:163].reshape((n_classes,))\n",
        "\n",
        "    # Perform forward propagation\n",
        "    z1 = X.dot(W1) + b1  # Pre-activation in Layer 1\n",
        "    a1 = np.tanh(z1)     # Activation in Layer 1\n",
        "    z2 = a1.dot(W2) + b2 # Pre-activation in Layer 2\n",
        "    logits = z2          # Logits for Layer 2\n",
        "\n",
        "    # Compute for the softmax of the logits\n",
        "    exp_scores = np.exp(logits)\n",
        "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
        "\n",
        "    # Compute for the negative log likelihood\n",
        "    N = 150 # Number of samples\n",
        "    corect_logprobs = -np.log(probs[range(N), y])\n",
        "    loss = np.sum(corect_logprobs) / N\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "KDJJeq154rc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x):\n",
        "    \"\"\"Higher-level method to do forward_prop in the\n",
        "    whole swarm.\n",
        "\n",
        "    Inputs\n",
        "    ------\n",
        "    x: numpy.ndarray of shape (n_particles, dimensions)\n",
        "        The swarm that will perform the search\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    numpy.ndarray of shape (n_particles, )\n",
        "        The computed loss for each particle\n",
        "    \"\"\"\n",
        "    n_particles = x.shape[0]\n",
        "    j = [forward_prop(x[i]) for i in range(n_particles)]\n",
        "    return np.array(j)"
      ],
      "metadata": {
        "id": "6oJCudQw54fH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize swarm\n",
        "options = {'c1': 0.5, 'c2': 0.3, 'w':0.9}\n",
        "\n",
        "# Call instance of PSO\n",
        "dimensions = (4 * 20) + (20 * 3) + 20 + 3\n",
        "optimizer = ps.single.GlobalBestPSO(n_particles=100, dimensions=dimensions, options=options)\n",
        "\n",
        "# Perform optimization\n",
        "cost, pos = optimizer.optimize(objective_func=f, iters=1000, verbose=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jp9rEb1_57TB",
        "outputId": "83908c3a-3656-4553-cf7b-10040467357a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-01-27 23:54:39,334 - pyswarms.single.global_best - INFO - Optimize for 1000 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n",
            "pyswarms.single.global_best: 100%|██████████|1000/1000, best_cost=0.00275\n",
            "2022-01-27 23:55:08,915 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.0027495354316405605, best pos: [-1.98077318e-01 -7.98043169e-01 -5.93924042e-01  3.46552785e-01\n",
            "  1.02891541e+00  4.78867365e-01 -3.92334277e-01  3.01152763e-01\n",
            " -1.18260051e+00  8.93320145e-01 -6.68367589e-01 -2.63540203e+00\n",
            "  1.62905930e+00 -4.98823018e-01 -4.97724130e-01  6.00572593e-01\n",
            "  5.31562201e-01  2.76627278e+00 -3.84580222e-01  4.14006362e-01\n",
            "  2.00943944e-02 -6.95539689e+00  1.24162557e+00  1.11867417e+00\n",
            "  2.30303891e+00  1.51731045e+00  4.97555584e+00  1.15499545e+00\n",
            "  1.77568057e+00 -3.86254543e-01  7.69681671e-01 -1.62539823e-01\n",
            "  3.10468944e+00 -4.43932115e-01  1.20149355e+00  1.16204714e+00\n",
            "  4.55443399e-01  2.18681285e+00  3.21939786e-01  3.67189729e+00\n",
            "  2.94243029e+00 -2.02645589e+00  9.27205611e-01 -1.49597051e+00\n",
            "  1.43016045e+00  5.34564794e-01  1.90700381e+00 -2.10419146e+00\n",
            "  1.08428518e+00 -1.80184131e-01  4.09413537e-01  4.09443751e-01\n",
            " -1.04576767e+00  1.72701838e+00 -1.08412393e+00  1.06376915e+00\n",
            " -2.46098231e+00 -3.93683403e+00  1.77198273e+00  4.27320578e+00\n",
            " -1.22138490e+00 -2.70156401e-01  3.03674829e+00  1.72697634e+00\n",
            " -1.13860100e+01 -5.67193500e-01 -2.51171809e-01 -4.72541275e-01\n",
            "  1.03266944e+00 -5.43499233e-01  6.01354678e-02 -8.82236499e-01\n",
            " -3.15305172e+00  7.19045365e-01 -2.67139283e+00 -1.98236050e+00\n",
            " -4.55454100e-01  9.53030536e-01  3.10120330e-01  4.80196357e-02\n",
            " -1.24831562e-01  2.04142815e-01 -3.70902650e+00 -1.35295185e+00\n",
            "  8.53309653e-01  1.82372216e+00  1.20772233e+00  2.78260784e-01\n",
            "  3.87655983e-01 -1.68628176e+00  3.71173559e-01 -2.89136382e+00\n",
            " -2.95098127e-01  3.86430375e-01  8.57189855e+00 -1.92587171e+00\n",
            "  8.35252797e+00 -7.63133854e-01  7.59423258e-01  3.07428727e-01\n",
            "  2.20527146e-01 -3.31987625e+00 -3.04681377e-01 -1.74698958e+00\n",
            "  3.41879299e+00  2.44446403e+00 -2.63358111e+00  5.90649409e-01\n",
            "  1.18348668e+00  1.94993140e+00  8.29296332e-01  1.21253295e-01\n",
            "  2.35415535e+00  2.62806446e+00 -5.34564276e+01 -5.05479039e-02\n",
            "  1.04028075e+01  9.28663021e-01 -5.11174682e-01 -4.71925920e+00\n",
            " -7.90683386e-02  3.23263291e+00 -1.71330461e+01 -8.68269188e-01\n",
            " -3.62180858e-01 -7.52590302e-01  3.03877390e-01 -6.88665644e+01\n",
            " -8.21975409e+01  3.47295343e-01 -1.72343868e+00 -7.31743334e-01\n",
            "  1.33360076e-01  2.12179397e+00  3.89725239e-01 -2.03744350e-01\n",
            "  2.58566940e-01  6.59131397e-01  1.09365036e-01  1.40030390e+00\n",
            " -8.19118020e-01  1.07438682e+00 -2.84656149e-01 -1.85679070e+00\n",
            " -1.52067174e+00 -7.57502127e-01 -1.06914183e+00 -2.25405525e+00\n",
            "  6.52201345e-01  2.15675823e+01 -1.58701384e+00 -7.05394349e-01\n",
            " -1.03925498e+00 -4.76867601e+00  9.61166671e-03 -3.01041042e-01\n",
            " -8.51581346e-01  2.01158799e-01  3.28751057e-01  4.52559723e-01\n",
            " -1.12091182e+00 -9.70826150e-01  2.12608487e+00]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, pos):\n",
        "    \"\"\"\n",
        "    Use the trained weights to perform class predictions.\n",
        "\n",
        "    Inputs\n",
        "    ------\n",
        "    X: numpy.ndarray\n",
        "        Input Iris dataset\n",
        "    pos: numpy.ndarray\n",
        "        Position matrix found by the swarm. Will be rolled\n",
        "        into weights and biases.\n",
        "    \"\"\"\n",
        "    # Neural network architecture\n",
        "    n_inputs = 4\n",
        "    n_hidden = 20\n",
        "    n_classes = 3\n",
        "\n",
        "    # Roll-back the weights and biases\n",
        "    W1 = pos[0:80].reshape((n_inputs,n_hidden))\n",
        "    b1 = pos[80:100].reshape((n_hidden,))\n",
        "    W2 = pos[100:160].reshape((n_hidden,n_classes))\n",
        "    b2 = pos[160:163].reshape((n_classes,))\n",
        "\n",
        "    # Perform forward propagation\n",
        "    z1 = X.dot(W1) + b1  # Pre-activation in Layer 1\n",
        "    a1 = np.tanh(z1)     # Activation in Layer 1\n",
        "    z2 = a1.dot(W2) + b2 # Pre-activation in Layer 2\n",
        "    logits = z2          # Logits for Layer 2\n",
        "\n",
        "    y_pred = np.argmax(logits, axis=1)\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "tWV_JcfI5-eQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(predict(X, pos) == y).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DAFOG3A90yQ",
        "outputId": "ec94888f-8ad9-4e0c-ded8-734c7e9e63cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Сделайте краткий обзор научной работы, посвящённой алгоритму нейронных сетей, \t не рассматриваемому ранее на курсе. Проведите анализ: чем отличается выбранная архитектура от других? В чём плюсы и минусы данной архитектуры? Какие могут возникнуть трудности при её применении на практике?"
      ],
      "metadata": {
        "id": "ushOTu7YKHNp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Particle swarm optimizer эффективный механизм, исходя из статей, приведенных выше. Для более глубокого изучения была использована дополнительная [статья](https://kpfu.ru/staff_files/F_1407356997/overview.pdf), которая раскрывает суть PSO, но не стала доступной для моего индивидуального понимания."
      ],
      "metadata": {
        "id": "ptnhA7cbcg86"
      }
    }
  ]
}